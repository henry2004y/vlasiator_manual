<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/vlasiator_manual/libs/highlight/github.min.css"> <link rel=stylesheet  href="/vlasiator_manual/css/jtd.css"> <link rel=icon  href="/vlasiator_manual/assets/favicon.ico"> <title>Testing</title> <div class=page-wrap > <div class=side-bar > <div class=header > <a href="/vlasiator_manual/" class=title > Vlasiator </a> </div> <label for=show-menu  class=show-menu >MENU</label> <input type=checkbox  id=show-menu  role=button > <div class=menu  id=side-menu > <ul class=menu-list > <li class="menu-list-item "><a href="/vlasiator_manual/" class="menu-list-link ">Home</a> <li class="menu-list-item "><a href="/vlasiator_manual/menu1/" class="menu-list-link ">Installation</a> <li class="menu-list-item "><a href="/vlasiator_manual/menu2/" class="menu-list-link ">Run</a> <li class="menu-list-item "><a href="/vlasiator_manual/menu3/" class="menu-list-link ">Postprocessing</a> <li class="menu-list-item "><a href="/vlasiator_manual/menu4/" class="menu-list-link ">Internal</a> <ul class="menu-list-child-list "> <li class="menu-list-item "><a href="#" class=menu-list-link >SysBoundary</a> </ul> <li class="menu-list-item "><a href="/vlasiator_manual/menu5/" class="menu-list-link active">Misc</a> </ul> </div> <div class=footer > This is <em>Just the docs</em>, adapted from the <a href="https://github.com/pmarsceill/just-the-docs" target=_blank >Jekyll theme</a>. </div> </div> <div class=main-content-wrap > <div class=main-content > <div class=main-header > <a id=github  href="/vlasiator_manual//github.com/fmihpc/vlasiator">Vlasiator on GitHub</a> </div> <div class=franklin-content ><h1 id=testing ><a href="#testing" class=header-anchor >Testing</a></h1> <div class=franklin-toc ><ol><li><a href="#comparing_differences">Comparing Differences</a><li><a href="#demo">Demo</a></ol></div> <p>There exists some test funtionalities under the <code>testpackages</code> folder, but it is not good enough.</p> <ul> <li><p>Currently one can compare the output from one version of the code to another version, but obviously there are many problems with this approach. How can you guarantee the version you select generate the correct &quot;reference&quot; solutions?</p> <li><p>The shell scripts are written for specific machines, but none of them are running on a regular basis.</p> <li><p>One has to do many extra work to create tests on a new machine.</p> <li><p>We cannot pick a specific test to run easily with one command.</p> </ul> <p>To tackle these problems, I am thinking about redesign the whole test suites. The goal is to</p> <ul> <li><p>define reference solutions to compare with;</p> <li><p>create a flexible test list with <code>make</code>;</p> <li><p>test one thing at a time;</p> <li><p>introduce continuous integration &#40;CI&#41; to validate new development and changes.</p> </ul> <p>There is a tool written in C&#43;&#43; called <code>vlsvdiff</code> that can be used to compare two VLSV files. This can be used to investigate the differences between files. For automated tests, it is enough to know that there are differences. The difficulties for VLSV file format result from the random writing order from MPI processes. If you are running with multiple MPI processes, you may get different SHA values out of the VLSV file even if the data are actually identical.</p> <p>How to store the reference solutions? Well, they should be saved in a different repository to keep the main source repo clean. To compare results, more often than not we do not need the raw distribution values f: by not saving it we can save a lot of storage&#33;</p> <h2 id=comparing_differences ><a href="#comparing_differences" class=header-anchor >Comparing Differences</a></h2> <p>This is a big headache now. I get different results with different code versions on different platforms, even if there shouldn&#39;t be any.</p> <ol> <li><p>There are two GCC optimization flags that will affect the results even on the same machine with slightly differernt code versions: <code>-ffast-math</code>, which boost the floating point operation performance by loosening the IEEE standard; <code>-mavx</code>, which turns on the avx instructions on the target machine. I can understand the first, but not the second one. Both flags have influence on the speed beyond <code>-O3</code>, which are about 10&#37;. </p> <li><p>Even if I turn off all the optimization flags, there are still differences running on different machines for multiple tests, e.g. <code>acctest_1_maxw_500k_30kms_1deg</code>. Among all the variables being saved there, the largest difference comes from <code>populations_vg_rho_loss_adjust</code>, which records the sparse distribution dropping/adding. I don&#39;t have any idea how this can happen: maybe the values are so small, and the round-off errors accumulate with timesteps?</p> </ol> <h2 id=demo ><a href="#demo" class=header-anchor >Demo</a></h2> <p>Under the <code>testpackage</code> folder:</p> <pre><code class="shell hljs">make</code></pre>
<p>runs all the listed tests in <code>Makefile</code>.</p>
<pre><code class="shell hljs">make TESTS=flowthrough</code></pre>
<p>runs a specific test.</p>
<p>It would be nice to save the test log somewhere, but for now just ignore it. Also <code>vlsvdiff</code> can substitute julia for comparing differences.</p>
<div class=page-foot >
  <div class=copyright >
    &copy; Hongyang Zhou. Last modified: March 15, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
    </div> 
    </div> 
    </div> <!-- end of class page-wrap-->